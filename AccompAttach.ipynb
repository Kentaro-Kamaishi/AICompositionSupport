{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, LSTM, Input\n",
    "from keras.optimizers import RMSprop, Adadelta, Adam\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import music21 as m21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 音符・休符の文章への変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トラックの結合\n",
    "def concatenateTracks(path, trackNums):\n",
    "    track = m21.converter.parse(path)\n",
    "    p = m21.stream.Part(id=\"part\")\n",
    "    for i in trackNums:\n",
    "        piece = track.parts[int(i)-1]\n",
    "        for note in piece.flat.notes:\n",
    "            p.insert(note.offset, note)    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#今回はいきなり文章を作る\n",
    "unitlength = 2 #0.5小節\n",
    "music_keys = ('C')\n",
    "def TrackToStrList(path, trackNums):\n",
    "    track = m21.converter.parse(path)\n",
    "    piece = concatenateTracks(path, trackNums)#コードなので結合\n",
    "    TrackStr = [\"\"]*(int(piece.quarterLength/unitlength)+1) \n",
    "    #1回あたり何要素か\n",
    "    \n",
    "    for trans_key in music_keys:\n",
    "        k = piece.analyze('key')\n",
    "        trans = trans_key\n",
    "        \n",
    "        i = m21.interval.Interval(k.tonic, m21.pitch.Pitch(trans))\n",
    "        trans_piece = piece.transpose(i)\n",
    "        \n",
    "        for n in trans_piece.flat.notes:\n",
    "            notes = []\n",
    "            if isinstance(n, m21.note.Note):\n",
    "                notes = [n]\n",
    "            elif isinstance(n, m21.chord.Chord):\n",
    "                notes = [x for x in n]\n",
    "\n",
    "            offset = n.offset\n",
    "            for note in notes:\n",
    "                q = int(offset // unitlength)\n",
    "                r = offset % unitlength\n",
    "                TrackStr[q] += note.nameWithOctave + '_' + str(n.duration.quarterLength) + '_' + str(r) + ' '\n",
    "            #0.5小節(=4分音符2つ)単位で見たとき、先頭からどれくらい離れているか=オフセット\n",
    "    return TrackStr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#今回は1ファイルのみ対応(間に合ってなくてすみません...)\n",
    "InputSentences = TrackToStrList('../midi/元データ\\\\aogeba.mid',  ['1'])\n",
    "OutputSentences = TrackToStrList('../midi/元データ\\\\aogeba.mid', ['3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主旋律と伴奏の組を作る\n",
    "meloStart = 0\n",
    "while InputSentences[meloStart] == '':\n",
    "    meloStart += 1\n",
    "meloEnd = len(InputSentences)-1\n",
    "while InputSentences[meloEnd] == '':\n",
    "    meloEnd -= 1\n",
    "\n",
    "InputSentences = InputSentences[meloStart:meloEnd+1]\n",
    "OutputSentences = [\"\\t \"+s+\"\\n\" for s in OutputSentences[meloStart:meloEnd+1]]\n",
    "\n",
    "print(InputSentences)\n",
    "print(OutputSentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辞書の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input=メロディ, output=伴奏の2種類を作成\n",
    "count = 0\n",
    "input_token_indices = {}\n",
    "InputChars = ''.join(InputSentences).split()\n",
    "OutputChars = ''.join(OutputSentences).split()\n",
    "\n",
    "for word in InputChars:\n",
    "    if not word+' ' in input_token_indices:\n",
    "        input_token_indices[word+' '] = count #key=word, value=count\n",
    "        count += 1\n",
    "count = 0\n",
    "output_token_indices = {}\n",
    "\n",
    "for word in OutputChars:\n",
    "    if not word+' ' in output_token_indices:\n",
    "        output_token_indices[word+' '] = count #key=word, value=count\n",
    "        count += 1\n",
    "output_token_indices['\\t '] = count\n",
    "output_token_indices['\\n'] = count+1\n",
    "\n",
    "#逆引き辞書の作成\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_indices.items())\n",
    "reverse_output_char_index = dict(\n",
    "    (i, char) for char, i in output_token_indices.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hotベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(input_token_indices)\n",
    "num_decoder_tokens = len(output_token_indices)\n",
    "encoder_maxlen = max([len(txt.split()) for txt in InputSentences])\n",
    "decoder_maxlen = max([len(txt.split(' ')) for txt in OutputSentences])\n",
    "num_sentences = len(InputSentences)\n",
    "print(\"nb sequences:\", num_sentences)\n",
    "\n",
    "print(\"Vectorization...\")\n",
    "encoder_input_data = np.zeros((num_sentences, encoder_maxlen, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((num_sentences, decoder_maxlen, num_decoder_tokens), dtype='float32')\n",
    "decoder_output_data = np.zeros((num_sentences, decoder_maxlen, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for i, (input_text, output_text) in enumerate(zip(InputSentences, OutputSentences)):\n",
    "    for t, char in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t, input_token_indices[char+' ']] = 1.\n",
    "    for t, char in enumerate(output_text.split(' ')):\n",
    "        if char != '\\n':\n",
    "            char += ' '\n",
    "        # decoder_output_dataはタイムステップが1遅れる\n",
    "        decoder_input_data[i, t, output_token_indices[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_output_data[i, t - 1, output_token_indices[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの作成・学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Build model...\")\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 500\n",
    "latent_dim = 15 #隠れ層の次元\n",
    "\n",
    "# エンコーダの作成\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# エンコーダの状態のみ保持 出力は捨てる\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# デコーダの作成\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states) #初期状態はエンコーダの最終状態\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    " \n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "stack = model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習曲線の描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(epochs)\n",
    "\n",
    "plt.plot(x, stack.history['accuracy'], label=\"accuracy\")\n",
    "plt.title(\"accuracy\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(x, stack.history['loss'], label=\"loss\")\n",
    "plt.title(\"loss\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "\n",
    "print(stack.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主旋律への伴奏付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds) #softmax関数の計算?\n",
    "    probas = np.random.multinomial(1, preds, 1) \n",
    "    #http://www.gentosha-academy.com/serial/okamoto-4/ にmultinomialの説明あり\n",
    "    #今回は1からkがpreds=[p1,p2,...,pk]という度数分布に従っているとき、\n",
    "    #1回(var1)試行を行ったときの度数分布が1サンプル(var3)得られる\n",
    "    return np.argmax(probas) #1になっている要素番号を返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論用のモデル作成\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    " \n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# 推論ではデコーダの状態も使う\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    " \n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    " \n",
    "    output_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    output_seq[0, 0, output_token_indices['\\t ']] = 1.\n",
    " \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [output_seq] + states_value) \n",
    "        #1回目の実行では、エンコーダ(メロディ)の予測と先頭文字だけのアウトプット(伴奏)をつなげる\n",
    " \n",
    "        sampled_token_index = sample(output_tokens[0, -1, :], 0.2)\n",
    "        sampled_char = reverse_output_char_index[sampled_token_index]\n",
    "        \n",
    "        #最大長に達するか終端文字が来たら生成終了\n",
    "        if sampled_char != '\\n':\n",
    "            decoded_sentence += sampled_char + ' '\n",
    "        else:\n",
    "            stop_condition = True\n",
    "        \n",
    "        if len(decoded_sentence.split()) > decoder_maxlen:\n",
    "            stop_condition = True\n",
    " \n",
    "        # 出力文字の更新\n",
    "        output_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        output_seq[0, 0, sampled_token_index] = 1.\n",
    " \n",
    "        # 状態の更新\n",
    "        states_value = [h, c]\n",
    " \n",
    "    return decoded_sentence\n",
    "\n",
    "#model = load_model('s2s.h5')\n",
    "\n",
    "import random\n",
    "input_sentence = []\n",
    "output_sentence = []\n",
    "for seq_index in range(num_sentences):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1] #encoder_input_dataの先頭0.5小節から順に生成\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', InputSentences[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    input_sentence.append(InputSentences[seq_index]) #入力文章を追加 \n",
    "    output_sentence.append(decoded_sentence) #生成結果を追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文字列をmidiに変換\n",
    "score = m21.stream.Score()\n",
    "meloPart = m21.stream.Part(id=\"melo\")\n",
    "accompPart = m21.stream.Part(id=\"accomp\")\n",
    "\n",
    "#主旋律のトラック作成\n",
    "melo = input_sentence\n",
    "offset = 0\n",
    "for i, ms in enumerate(melo):\n",
    "    for m in ms.split():\n",
    "        pitch, length, _offset = m.split('_')\n",
    "\n",
    "        tmp = length.split('/')\n",
    "        if len(tmp) == 2:\n",
    "            length = float(tmp[0])/float(tmp[1])\n",
    "        else:\n",
    "            length = float(tmp[0])\n",
    "\n",
    "        offset = float(_offset)\n",
    "        n = m21.note.Note(pitch, quarterLength=length)\n",
    "        meloPart.insert(i*unitlength+offset,n)\n",
    "\n",
    "#伴奏のトラック作成\n",
    "accomp = output_sentence\n",
    "offset = 0\n",
    "for i, ms in enumerate(accomp):\n",
    "    for m in ms.split():\n",
    "        pitch, length, _offset = m.split('_')\n",
    "\n",
    "        tmp = length.split('/')\n",
    "        if len(tmp) == 2:\n",
    "            length = float(tmp[0])/float(tmp[1])\n",
    "        else:\n",
    "            length = float(tmp[0])\n",
    "\n",
    "        offset = float(_offset)\n",
    "        n = m21.note.Note(pitch, quarterLength=length)\n",
    "        accompPart.insert(i*unitlength+offset,n)\n",
    "        \n",
    "score.insert(0, meloPart)\n",
    "score.insert(0, accompPart)\n",
    "score.show(\"midi\")\n",
    "score.write(fmt=\"midi\", fp=\"./s2s.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
